{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9f453b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (1.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (0.4.37)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (2.12.3)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langchain-core) (0.12.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.25.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.4 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.4)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: anyio in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.5.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#!pip install -U ddgs\n",
    "# %pip install -U langchain-google-vertexai\n",
    "# %pip install --upgrade langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef8d0b40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Langchain-Tutorial/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os, getpass\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI #BaseChatModel\n",
    "load_dotenv()  # Loads environment variables from .env file\n",
    "# ignore all warnings in this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e0120e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.agents import create_agent\n",
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c443b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY not found in .env file.\n"
     ]
    }
   ],
   "source": [
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if google_api_key:\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
    "    print(\"GOOGLE_API_KEY found in .env file.\")\n",
    "else:\n",
    "    print(\"GOOGLE_API_KEY not found in .env file.\")\n",
    "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter GEMINI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73900c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1765363767.300886    1681 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44930d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools Creation\n",
    "from langchain.tools import tool\n",
    "from datetime import datetime\n",
    "import random\n",
    "\n",
    "@tool\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"Search the web for current information.\n",
    "    \n",
    "    Args:\n",
    "        query: The search query string\n",
    "        \n",
    "    Returns:\n",
    "        Search results as a string\n",
    "    \"\"\"\n",
    "    # In production, you'd use a real search API\n",
    "    # For demo purposes, we'll simulate results\n",
    "    simulated_results = {\n",
    "        \"weather\": \"Current weather: Sunny, 72Â°F in San Francisco\",\n",
    "        \"news\": \"Latest AI news: New GPT model released with improved reasoning\",\n",
    "        \"stocks\": \"Tech stocks up 2.5% today, AI sector leading gains\"\n",
    "    }\n",
    "    \n",
    "    for key in simulated_results:\n",
    "        if key in query.lower():\n",
    "            return simulated_results[key]\n",
    "    \n",
    "    return f\"Search results for '{query}': Found 10 relevant articles...\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculator(expression: str) -> str:\n",
    "    \"\"\"Perform mathematical calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate\n",
    "        \n",
    "    Returns:\n",
    "        The calculation result\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Safe evaluation of mathematical expressions\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"Result: {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error calculating: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def get_current_time(timezone: str = \"UTC\") -> str:\n",
    "    \"\"\"Get the current time in a specific timezone.\n",
    "    \n",
    "    Args:\n",
    "        timezone: The timezone (default: UTC)\n",
    "        \n",
    "    Returns:\n",
    "        Current time as a string\n",
    "    \"\"\"\n",
    "    current_time = datetime.now()\n",
    "    return f\"Current time in {timezone}: {current_time.strftime('%Y-%m-%d %H:%M:%S')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38f26190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool: search_web\n",
      "  Description: Search the web for current information.\n",
      "\n",
      "    Args:\n",
      "        query: The search query string\n",
      "\n",
      "    Returns:\n",
      "        Search results as a string\n",
      "  Input schema: <class 'langchain_core.utils.pydantic.search_web'>\n",
      "\n",
      "Tool: calculator\n",
      "  Description: Perform mathematical calculations.\n",
      "\n",
      "    Args:\n",
      "        expression: A mathematical expression to evaluate\n",
      "\n",
      "    Returns:\n",
      "        The calculation result\n",
      "  Input schema: <class 'langchain_core.utils.pydantic.calculator'>\n",
      "\n",
      "Tool: get_current_time\n",
      "  Description: Get the current time in a specific timezone.\n",
      "\n",
      "    Args:\n",
      "        timezone: The timezone (default: UTC)\n",
      "\n",
      "    Returns:\n",
      "        Current time as a string\n",
      "  Input schema: <class 'langchain_core.utils.pydantic.get_current_time'>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all tool metadata\n",
    "tools=[search_web, calculator, get_current_time]\n",
    "for tool_obj in tools:\n",
    "    print(f\"Tool: {tool_obj.name}\")\n",
    "    print(f\"  Description: {tool_obj.description}\")\n",
    "    print(f\"  Input schema: {tool_obj.args_schema}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3e86bb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Creation\n",
    "# Create the agent with tools\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_web, calculator, get_current_time],\n",
    "    system_prompt=\"\"\"You are a helpful AI assistant with access to tools.\n",
    "    \n",
    "    You can:\n",
    "    - Search the web for current information\n",
    "    - Perform calculations\n",
    "    - Get the current time\n",
    "    \n",
    "    Think step-by-step and use tools when needed to provide accurate answers.\n",
    "    Be concise but thorough.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14646771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple tool use\n",
    "def run_agent(user_message: str):\n",
    "    \"\"\"Run the agent with a user message.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"USER: {user_message}\")\n",
    "    print(f\"{'='*60}\\n\")\n",
    "    \n",
    "    result = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": user_message}]\n",
    "    })\n",
    "    \n",
    "    # Print the agent's response\n",
    "    final_message = result[\"messages\"][-1]\n",
    "    print(f\"AGENT: {final_message.content}\\n\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fea35421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: What time is it ?\n",
      "============================================================\n",
      "\n",
      "AGENT: The current time is 10:51:22 UTC on December 10, 2025.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What time is it ?', additional_kwargs={}, response_metadata={}, id='4f9f4ea4-28b8-49c1-8d26-15deb01735bc'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_time', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07e3-1538-7b42-96ab-547ab39a58bb-0', tool_calls=[{'name': 'get_current_time', 'args': {}, 'id': '252d2f28-39fa-4956-8723-63e314e9fadc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 259, 'output_tokens': 60, 'total_tokens': 319, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 48}}),\n",
       "  ToolMessage(content='Current time in UTC: 2025-12-10 10:51:22', name='get_current_time', id='1d631408-17fb-49e1-a1c8-71faa8b21e36', tool_call_id='252d2f28-39fa-4956-8723-63e314e9fadc'),\n",
       "  AIMessage(content='The current time is 10:51:22 UTC on December 10, 2025.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07e3-1b58-7d01-bb86-cfa62f2caa2d-0', usage_metadata={'input_tokens': 312, 'output_tokens': 26, 'total_tokens': 338, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 1: Time query\n",
    "run_agent(\"What time is it ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2178ac98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: If I buy 3 items at $24.99 each and have a 15% discount, what's my total?\n",
      "============================================================\n",
      "\n",
      "AGENT: Your total would be $63.72.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"If I buy 3 items at $24.99 each and have a 15% discount, what's my total?\", additional_kwargs={}, response_metadata={}, id='7129eaf7-31c3-4130-af97-df44f68d8e94'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"(3 * 24.99) * 0.85\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07ec-c6a2-7380-95e3-edd2526b9165-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '(3 * 24.99) * 0.85'}, 'id': '8b0186fb-66fb-452a-8489-f5092d447cf2', 'type': 'tool_call'}], usage_metadata={'input_tokens': 283, 'output_tokens': 205, 'total_tokens': 488, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 178}}),\n",
       "  ToolMessage(content='Result: 63.7245', name='calculator', id='67d7241a-5443-4fb1-80d0-119379ef14f0', tool_call_id='8b0186fb-66fb-452a-8489-f5092d447cf2'),\n",
       "  AIMessage(content='Your total would be $63.72.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07ec-cf49-74e3-849c-d1492005fc9d-0', usage_metadata={'input_tokens': 332, 'output_tokens': 11, 'total_tokens': 343, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 2: Calculation\n",
    "run_agent(\"If I buy 3 items at $24.99 each and have a 15% discount, what's my total?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60456ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Web search\n",
    "run_agent(\"What's the weather like today in San Fransico?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a831545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Search for AI news, then calculate how many days until the end of the year\n",
      "============================================================\n",
      "\n",
      "AGENT: AI news: A new GPT model has been released with improved reasoning capabilities. There are 21 days until the end of the year.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Search for AI news, then calculate how many days until the end of the year', additional_kwargs={}, response_metadata={}, id='e729bbab-513a-4908-9750-fe11ae3ac75c'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_time', 'arguments': '{\"timezone\": \"America/New_York\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07db-d7ee-7631-9f0d-2afe31c090f2-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'AI news'}, 'id': '1c470773-3356-4ced-b7d5-0041249702c8', 'type': 'tool_call'}, {'name': 'get_current_time', 'args': {'timezone': 'America/New_York'}, 'id': 'de8935e3-d580-49d5-ba29-a283a4214991', 'type': 'tool_call'}], usage_metadata={'input_tokens': 270, 'output_tokens': 37, 'total_tokens': 307, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Latest AI news: New GPT model released with improved reasoning', name='search_web', id='4ddaa741-dc7a-4124-be81-49a8736b7933', tool_call_id='1c470773-3356-4ced-b7d5-0041249702c8'),\n",
       "  ToolMessage(content='Current time in America/New_York: 2025-12-10 10:43:27', name='get_current_time', id='d8ee66df-d193-400c-bd19-59ab10286f31', tool_call_id='de8935e3-d580-49d5-ba29-a283a4214991'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'calculator', 'arguments': '{\"expression\": \"365 - 344\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07db-dae6-70d3-a485-f6c1f9314f84-0', tool_calls=[{'name': 'calculator', 'args': {'expression': '365 - 344'}, 'id': '112753de-155d-4bd9-85b2-208940d7ab5a', 'type': 'tool_call'}], usage_metadata={'input_tokens': 375, 'output_tokens': 20, 'total_tokens': 395, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Result: 21', name='calculator', id='c143d246-6c17-4761-9598-e4d06181faf3', tool_call_id='112753de-155d-4bd9-85b2-208940d7ab5a'),\n",
       "  AIMessage(content='AI news: A new GPT model has been released with improved reasoning capabilities. There are 21 days until the end of the year.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash-lite', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b07db-de32-7eb0-b68d-c4f131b913f7-0', usage_metadata={'input_tokens': 412, 'output_tokens': 28, 'total_tokens': 440, 'input_token_details': {'cache_read': 0}})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 3: Multi-step reasoning\n",
    "run_agent(\"Search for AI news, then calculate how many days until the end of the year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea428eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "USER: Search for AI news, then calculate how many days until the end of the year\n",
      "============================================================\n",
      "\n",
      "AGENT: [{'type': 'text', 'text': 'Latest AI news: New GPT model released with improved reasoning.\\n\\nThere are 22 days until the end of the year.', 'extras': {'signature': 'CsUDAXLI2nzktJ0uTLOEXb2RqV1t97+cfHuWONA019uF6KO/Lkmw4Mvls97wKoyOg1iXGP9yx17Z7jM2EMaL0NvjhYzYtkovBc2sRhQ6f8dEc0LlJm/jdynnndjPU35DwNPlCqdPoH9NeAzVXYJwuKnxjoQ9vSlBtHKT/rT1HGXDmRW/HCFlCJKK8ygr/avn+AySGOx1tMAxVE6lY9FeA46hzptVZXNeHAMIBTXbXdZKzZMwM28zLGcAqBTu0JYqi8Ngl/eVzg6UMS39lhWunjv72REnraYlCT/HKd/kLXmKwC2gYXZ4JoGV4sjJOm5xb3FkoCcWgw/PMXx1GfMCH7ha+dsRvREpe4/wOaHR+tGloo5HcDSWnv179cvx9i6FNeMZ0djmTlDM6+P2dP2bRKwUlH3KJnHet/KVwyBYbd9hlC2NMiIuX9iC5mt7auriW9vx1vQuUif+bBAWCOzEnWU5qgWi22A/Lwm/fFLa6k9n6m3zv/0vZVpuQG6iLWbB4kQ856AjruLOMz15KnjhFbWKHGK9SxktMn4Q9u18mixw4YClye+gvu+O3TFqkk3sQtlbd6rqwSl63QKiuAQHJxY/cCcUmXLt'}}]\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Search for AI news, then calculate how many days until the end of the year', additional_kwargs={}, response_metadata={}, id='56439c0c-c874-405d-863b-bcae21e3988a'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'search_web', 'arguments': '{\"query\": \"AI news\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b0395-74e6-7163-a952-0d5f89761282-0', tool_calls=[{'name': 'search_web', 'args': {'query': 'AI news'}, 'id': '757dceff-8585-4a60-aa76-caeddf298540', 'type': 'tool_call'}], usage_metadata={'input_tokens': 270, 'output_tokens': 149, 'total_tokens': 419, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 133}}),\n",
       "  ToolMessage(content='Latest AI news: New GPT model released with improved reasoning', name='search_web', id='7a1d4c12-e79f-4a70-b90b-66a5f958173b', tool_call_id='757dceff-8585-4a60-aa76-caeddf298540'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'get_current_time', 'arguments': '{}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b0395-7bd5-7ca1-a50b-5faf16c300e9-0', tool_calls=[{'name': 'get_current_time', 'args': {}, 'id': '81bc033d-07df-4a7f-a04a-9b4d05bd4d05', 'type': 'tool_call'}], usage_metadata={'input_tokens': 311, 'output_tokens': 100, 'total_tokens': 411, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 88}}),\n",
       "  ToolMessage(content='Current time in UTC: 2025-12-09 14:48:12', name='get_current_time', id='d24eede9-37d0-4a2a-8d4f-c04a94283fd1', tool_call_id='81bc033d-07df-4a7f-a04a-9b4d05bd4d05'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': 'Latest AI news: New GPT model released with improved reasoning.\\n\\nThere are 22 days until the end of the year.', 'extras': {'signature': 'CsUDAXLI2nzktJ0uTLOEXb2RqV1t97+cfHuWONA019uF6KO/Lkmw4Mvls97wKoyOg1iXGP9yx17Z7jM2EMaL0NvjhYzYtkovBc2sRhQ6f8dEc0LlJm/jdynnndjPU35DwNPlCqdPoH9NeAzVXYJwuKnxjoQ9vSlBtHKT/rT1HGXDmRW/HCFlCJKK8ygr/avn+AySGOx1tMAxVE6lY9FeA46hzptVZXNeHAMIBTXbXdZKzZMwM28zLGcAqBTu0JYqi8Ngl/eVzg6UMS39lhWunjv72REnraYlCT/HKd/kLXmKwC2gYXZ4JoGV4sjJOm5xb3FkoCcWgw/PMXx1GfMCH7ha+dsRvREpe4/wOaHR+tGloo5HcDSWnv179cvx9i6FNeMZ0djmTlDM6+P2dP2bRKwUlH3KJnHet/KVwyBYbd9hlC2NMiIuX9iC5mt7auriW9vx1vQuUif+bBAWCOzEnWU5qgWi22A/Lwm/fFLa6k9n6m3zv/0vZVpuQG6iLWbB4kQ856AjruLOMz15KnjhFbWKHGK9SxktMn4Q9u18mixw4YClye+gvu+O3TFqkk3sQtlbd6rqwSl63QKiuAQHJxY/cCcUmXLt'}}], additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.5-flash', 'safety_ratings': [], 'grounding_metadata': {}, 'model_provider': 'google_genai'}, id='lc_run--019b0395-9039-7890-bfcb-2e1c28b51d9d-0', usage_metadata={'input_tokens': 364, 'output_tokens': 151, 'total_tokens': 515, 'input_token_details': {'cache_read': 0}, 'output_token_details': {'reasoning': 125}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 3: Multi-step reasoning\n",
    "run_agent(\"Search for AI news, then calculate how many days until the end of the year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7abbb73c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STREAMING DEMO: Watch the agent think!\n",
      "============================================================\n",
      "\n",
      "ðŸ’­ Agent: Calculate 15% of 299, then tell me the time\n",
      "ðŸ”§ Using tools: calculator, get_current_time\n",
      "ðŸ’­ Agent: Current time in UTC: 2025-12-10 10:45:42\n",
      "ðŸ’­ Agent: 15% of 299 is 44.85. The current time is 10:45:42 UTC.\n"
     ]
    }
   ],
   "source": [
    "# Streaming\n",
    "\n",
    "# Streaming example\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STREAMING DEMO: Watch the agent think!\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for chunk in agent.stream({\n",
    "    \"messages\": [{\"role\": \"user\", \"content\": \"Calculate 15% of 299, then tell me the time\"}]\n",
    "}, stream_mode=\"values\"):\n",
    "    latest_message = chunk[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(latest_message, 'content') and latest_message.content:\n",
    "        print(f\"ðŸ’­ Agent: {latest_message.content}\")\n",
    "    elif hasattr(latest_message, 'tool_calls') and latest_message.tool_calls:\n",
    "        tool_names = [tc['name'] for tc in latest_message.tool_calls]\n",
    "        print(f\"ðŸ”§ Using tools: {', '.join(tool_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Middleware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f4603291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool error handling\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_tool_call\n",
    "from langchain.messages import ToolMessage\n",
    "@tool\n",
    "def divide_numbers(a: float, b: float) -> str:\n",
    "    \"\"\"Divide two numbers. Will fail if dividing by zero.\n",
    "    \n",
    "    Args:\n",
    "        a: The numerator\n",
    "        b: The denominator\n",
    "    \"\"\"\n",
    "    result = a / b  # This will raise ZeroDivisionError if b=0\n",
    "    return f\"Result: {result}\"\n",
    "\n",
    "@wrap_tool_call\n",
    "def handle_tool_errors(request, handler):\n",
    "    \"\"\"Gracefully handle tool failures.\"\"\"\n",
    "    try:\n",
    "        return handler(request)\n",
    "    except Exception as e:\n",
    "        return ToolMessage(\n",
    "            content=f\"Tool failed: {str(e)}. Please try a different approach.\",\n",
    "            tool_call_id=request.tool_call[\"id\"]\n",
    "        )\n",
    "\n",
    "# Add error handling to agent\n",
    "agent_with_errors = create_agent(\n",
    "    model=model,\n",
    "    tools=[divide_numbers],\n",
    "    middleware=[handle_tool_errors],\n",
    "    system_prompt=\"You are a helpful assistant...\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce2a222",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_with_errors.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"2/0\"}]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f9000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c4a504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic model\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse\n",
    "\n",
    "\n",
    "basic_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "advanced_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "@wrap_model_call\n",
    "def smart_model_selection(request: ModelRequest, handler) -> ModelResponse:\n",
    "    \"\"\"Use basic model for simple queries, advanced for complex ones.\"\"\"\n",
    "    message_count = len(request.state[\"messages\"])\n",
    "    \n",
    "    # Use advanced model for longer conversations\n",
    "    if message_count > 5:\n",
    "        request.model = advanced_model\n",
    "    else:\n",
    "        request.model = basic_model\n",
    "    \n",
    "    return handler(request)\n",
    "\n",
    "agent_smart = create_agent(\n",
    "    model=basic_model,\n",
    "    tools=[search_web, calculator, get_current_time],\n",
    "    middleware=[smart_model_selection]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ab970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dyanmic System Prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic system prompt\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import dynamic_prompt, ModelRequest\n",
    "\n",
    "\n",
    "class Context(TypedDict):\n",
    "    user_role: str\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    base_prompt = \"You are a helpful assistant.\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply and avoid jargon.\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "\n",
    "@dynamic_prompt\n",
    "def user_role_prompt(request: ModelRequest) -> str:\n",
    "    \"\"\"Generate system prompt based on user role and available tools.\"\"\"\n",
    "    user_role = request.runtime.context.get(\"user_role\", \"user\")\n",
    "    tools_list = \", \".join([tool.__name__ for tool in request.runtime.tools])\n",
    "    \n",
    "    base_prompt = f\"You are a helpful assistant with access to tools: {tools_list}.\"\n",
    "\n",
    "    if user_role == \"expert\":\n",
    "        return f\"{base_prompt} Provide detailed technical responses and leverage tools effectively.\"\n",
    "    elif user_role == \"beginner\":\n",
    "        return f\"{base_prompt} Explain concepts simply, avoid jargon, and use tools only when necessary.\"\n",
    "\n",
    "    return base_prompt\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[search_web, calculator, get_current_time],\n",
    "    middleware=[user_role_prompt],\n",
    "    context_schema=Context\n",
    ")\n",
    "\n",
    "# The system prompt will be set dynamically based on context\n",
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"If I buy 3 items at $24.99 each and have a 15% discount, what's my total?\"}]},\n",
    "    context={\"user_role\": \"expert\"}\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
